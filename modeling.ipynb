{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Restaurant Recommendation Model\n",
    "\n",
    "## Purpose\n",
    "This Python notebook is dedicated to building and training the machine learning model used as the backend for the Restaurant Recommendation System. The goal is to create a robust recommendation system that suggests restaurants based on user preferences, historical data, and other relevant features.\n",
    "\n",
    "## Frameworks Used\n",
    "Built with sci.kit learn and associated libraries. The cosine similarity vector model was used to build this system."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import Relevant Packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                       name         city state  postal_code   latitude  \\\n",
      "0              Metro Grille     Flanders    NJ         7836  39.949904   \n",
      "1  Helen's Cafe and Gardens      Alloway    NJ         8001  39.563830   \n",
      "2       Alloway Village Inn      Alloway    NJ         8001  39.555717   \n",
      "3                McDonald's  Cherry Hill    NJ         8002  39.936079   \n",
      "4              Little Tokyo  Cherry Hill    NJ         8002  39.943728   \n",
      "\n",
      "   longitude  stars  review_count  \\\n",
      "0 -75.161599    3.0            17   \n",
      "1 -75.363824    4.0             5   \n",
      "2 -75.360766    3.5            13   \n",
      "3 -75.044117    2.5            18   \n",
      "4 -75.026066    4.0            12   \n",
      "\n",
      "                                          categories  B01001_001E  ...  \\\n",
      "0          Restaurants, Asian Fusion, American (New)        12034  ...   \n",
      "1  Restaurants, Cafes, Breakfast & Brunch, Venues...          835  ...   \n",
      "2  American (Traditional), Restaurants, Bars, Nig...          835  ...   \n",
      "3  Burgers, Food, Restaurants, Fast Food, Coffee ...        23630  ...   \n",
      "4                  Japanese, Sushi Bars, Restaurants        23630  ...   \n",
      "\n",
      "   S1903_C03_032E  S1903_C03_033E  S1903_C03_034E  S1903_C03_035E  \\\n",
      "0          182798          241500           75721           42083   \n",
      "1          136579               -           69773               -   \n",
      "2          136579               -           69773               -   \n",
      "3          126982          161806           53500           48480   \n",
      "4          126982          161806           53500           48480   \n",
      "\n",
      "   S1903_C03_036E  S1903_C03_037E  S1903_C03_038E  S1903_C03_039E  \\\n",
      "0           42083               -          100134          100938   \n",
      "1               -               -               -               -   \n",
      "2               -               -               -               -   \n",
      "3           47049          100698           63438           40616   \n",
      "4           47049          100698           63438           40616   \n",
      "\n",
      "   S1903_C03_040E  star_count  \n",
      "0               -        51.0  \n",
      "1               -        20.0  \n",
      "2               -        45.5  \n",
      "3          136477        45.0  \n",
      "4          136477        48.0  \n",
      "\n",
      "[5 rows x 154 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/6l/xb2bmr4d5718m4gjtrxd8h2w0000gn/T/ipykernel_34115/1506284659.py:2: DtypeWarning: Columns (116,117,123,124,125,127,128,129,130,132,133,139,140,145,146,147,149,150,153,154) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  complete = pd.read_csv(\"./data/restaurantdemo.csv\") #Directory\n"
     ]
    }
   ],
   "source": [
    "#Read Pandas Dataframe\n",
    "complete = pd.read_csv(\"./data/restaurantdemo.csv\") #Directory\n",
    "complete = complete.drop(columns=['business_id', 'GEO_ID', 'address'])\n",
    "complete = complete.head(20000)\n",
    "\n",
    "print(complete.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sk.Learn Imports\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Boosting Regressor Sk.Learn\n",
    "y = complete['stars']\n",
    "X = complete.drop(columns=['star_count', 'stars'])\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error: 0.43657840168681056\n"
     ]
    }
   ],
   "source": [
    "# Split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Text Columns\n",
    "text_features = ['name', 'city', 'categories', 'address']\n",
    "\n",
    "numeric_features = X_train.select_dtypes(include=['number']).columns\n",
    "\n",
    "#TF-IDF\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', 'passthrough', numeric_features),\n",
    "        ('name', TfidfVectorizer(), 'name'),\n",
    "        ('city', TfidfVectorizer(), 'city'),\n",
    "        ('categories', TfidfVectorizer(), 'categories'),\n",
    "    ])\n",
    "\n",
    "gb_model = GradientBoostingRegressor(n_estimators=100, learning_rate=0.1, random_state=42)\n",
    "\n",
    "model = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                        ('regressor', gb_model)])\n",
    "\n",
    "#Train\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "#Evaluate\n",
    "predictions = model.predict(X_test)\n",
    "mse = mean_squared_error(y_test, predictions)\n",
    "print(f'Mean Squared Error: {mse}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BERT Shenanigans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mihir/Library/Python/3.9/lib/python/site-packages/urllib3/__init__.py:34: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n",
      "/Users/mihir/Library/Python/3.9/lib/python/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertTokenizer, BertModel\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "model = BertModel.from_pretrained('bert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# Text Columns\n",
    "text_features = ['name', 'city', 'categories']\n",
    "bert_embeddings_list = []\n",
    "\n",
    "for column in text_features:\n",
    "    tokenized = tokenizer(complete[column].tolist(), return_tensors='pt', padding=True, truncation=True)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**tokenized)\n",
    "\n",
    "    embeddings = outputs.last_hidden_state[:, 0, :]\n",
    "    bert_embeddings_list.append(embeddings.numpy())\n",
    "\n",
    "concatenated_embeddings = np.concatenate(bert_embeddings_list, axis=1)\n",
    "\n",
    "#New Columns\n",
    "new_column_names = [f'{col}_bert_embedding_{i}' for col in text_features for i in range(embeddings.shape[1])]\n",
    "\n",
    "#New DF\n",
    "bert_embeddings_df = pd.DataFrame(concatenated_embeddings, columns=new_column_names)\n",
    "\n",
    "df = pd.concat([complete, bert_embeddings_df], axis=1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
